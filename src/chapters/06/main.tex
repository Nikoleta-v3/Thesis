\chapter{Best Response Sequences in the Iterated Prisoner's Dilemma}\label{chapter:best_response_sequence}

\begin{center}
    The research reported in this Chapter has been carried out with:

    Axerod-Python library version: 4.2.0 \\
    Associated data set: \cite{Glynatsi2020_sequences} \\ \vspace{.5cm}
\end{center}

\section{Introduction}

In this Chapter best response strategies are explored in the form
of static sequences of moves, in order to generate a large data set of best
response sequences to a collection of opponents.

The data set is generated by considering best response sequences in finite IPD
matches of 205 turns against \numberofstrategiesbestsequences strategies
available in the APL. These best response sequences are not obtained explicitly
but instead are estimated heuristically using a genetic algorithm devised for
this purpose.

The purpose of a large collection of best response sequences is
to serve as training data in Chapter~\ref{chapter:lstm} which aims to train a
recurrent neural network as an IPD strategy. In Chapter~\ref{chapter:lstm} the
usage of the bespoke data set, which has been archived and made publicly
available~\cite{Glynatsi2020_sequences}, is be discussed in more details. This
Chapter is structured as follow:

\begin{itemize}
    \item section~\ref{section:ipd_as_sequences} formalises the use of sequences to express a player in a
    finite IPD match.
    \item section~\ref{section:genetic_algorithm} describes the genetic algorithm
    used to estimate best response
    sequences.
    \item section~\ref{section:generating_sequences} details the process of
    generating best response sequences to a collection of
    \numberofstrategiesbestsequences strategies, and presents a brief analysis
    of its results.
\end{itemize}

\section{Iterated Prisoner Dilemma Strategies as Sequences}\label{section:ipd_as_sequences}

In a finite \(N\) round IPD match a player that does not react to their opponent
can be defined by a sequence,

\begin{equation}
    S \in \{C, D\} ^ n
\end{equation}

where \(n\) is the length of the sequence and \(1 \leq n \leq N\).

Strategies that play sequences, and more specifically play sequences periodically, are already established in the
literature~\cite{Beaufils1997}. These strategies include Periodic Player \(CD\), Periodic Player \(DC\),
Periodic Player \(CCD\) and Periodic Player \(DDC\)~\cite{Li2011, Mittal2009},
or as refereed to in~\cite{Knight2016} Cycler \(CD\), Cycler \(DC\),
Cycler \(CCD\) and Cycler \(DDC\). Similarly to these works, this Chapter will
consider strategies that play sequences, however for strictly \(n = N\), thus
a sequence is repeated once.

As an example of such a strategy consider a match of \(N = 10\) between the strategy \(S = \{D, D, D, C, C, C, D,
D, C, C\}\) and a Cooperator. The match between the two strategies is captured
by Table~\ref{table:s_vs_cooperator},

\begin{table}[htb]
\centering
\begin{tabular}{cccccccccccc}
    & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4}  & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8}  & \textbf{9} & \textbf{10} & 
    \(U(S, \text{Cooperator})\) \\ \midrule
    \(S\) & \(D\) & \(D\) & \(D\) & \(C\) & \(C\) & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & 4.0 \\
    Cooperator & \(C\) & \(C\) & \(C\) & \(C\) & \(C\) & \(C\) & \(C\) & \(C\) & \(C\) & \(C\) & 1.5 \\ \bottomrule
\end{tabular}
\caption{Match between \(S = \{D, D, D, C, C, C, D, D, C, C\}\) and Cooperator.}\label{table:s_vs_cooperator}
\end{table}

where \(U(s_1, s_2)\in \mathbb{R}^2\) is the average scores per turn scored by strategies \(s_1\) and \(s_2\).

A sequence strategy \(S\) can play against strategies that react to the history,
as demonstrated by Table~\ref{table:s_vs_tft}

\begin{table}[htb]
\centering
\begin{tabular}{cccccccccccc}
    & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4}  & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8}  & \textbf{9} & \textbf{10} &
    \(U(S, \text{Tit For Tat})\) \\ \midrule
    \(S\) & \(D\) & \(D\) & \(D\) & \(C\) & \(C\) & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & 2.2 \\
    Tit For Tat & \(C\) & \(D\) & \(D\) & \(D\) & \(C\) & \(C\) & \(C\) & \(D\) & \(D\) & \(C\) & 2.2 \\ \bottomrule
\end{tabular}
\caption{Match between \(S = \{D, D, D, C, C, C, D, D, C, C\}\) and Tit For Tat.}\label{table:s_vs_tft}
\end{table}

and against sophisticated strategies, such as Random with a probability \(0.5\)
of cooperating at each turn, Table~\ref{table:s_vs_random}.

\begin{table}[htb]
\centering
\begin{tabular}{cccccccccccc}
    & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4}  & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8}  & \textbf{9} & \textbf{10} &
    \(U(S, \text{Random})\) \\ \midrule
    \(S\) & \(D\) & \(D\) & \(D\) & \(C\) & \(C\) & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & 2.4 \\
    Random & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & 1.9 \\ \bottomrule
\end{tabular}
\caption{Match between \(S = \{D, D, D, C, C, C, D, D, C, C\}\) and Random.}\label{table:s_vs_random}
\end{table}

Note that the game of Table~\ref{table:s_vs_random} only captures a single
behaviour of Random against \(S = \{D, D, D, C, C, C, D, D, C, C\}\). Random is
a stochastic strategy, and thus the strategy's series of actions can differ even
when the history of plays is the same. For example Table~\ref{table:s_vs_random_2} demonstrates
another possible set of interactions between \(S\) and Random.

\begin{table}[htb]
    \centering
    \begin{tabular}{cccccccccccc}
        & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4}  & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8}  & \textbf{9} & \textbf{10} &
        \(U(S, \text{Random})\) \\ \midrule
        \(S\) & \(D\) & \(D\) & \(D\) & \(C\) & \(C\) & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & 2.4 \\
        Random & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & 1.9 \\ \bottomrule
    \end{tabular}
\caption{Match between \(S = \{D, D, D, C, C, C, D, D, C, C\}\) and Random.
The actions make by Random are different to that Table~\ref{table:s_vs_random} though the
actions of \(S\) are the same.}\label{table:s_vs_random_2}
 \end{table}

In section~\ref{section:generating_sequences} computer seeding is introduced.
Computer seeding allows this work to capture and reproduce several
instances/behaviour of stochastic strategies.

A best response sequence to a given opponent \(Q\) is the sequence for which the
average score per turn is maximised. More specifically,

\begin{equation}\label{eq:best_response}
    \begin{aligned}
    \max_{S^*}: & U(S^*, Q)
    \end{aligned}
\end{equation}

Identifying best responses to some opponents can be a trivial problem. The
optimal sequence against a Cooperator is in an all \(D\) sequence. In fact an
all \(D\) sequence is optimal against any sequence player whose plays are
independent of the history.  % TODO Chat about correct way to describe this mathematically.
There are strategies that have multiple best responses.
Adaptive, introduced in~\cite{Li2011}, opens by playing a sequence of \(\{\underbrace{C, \dots, C}_{6}\}\)
followed by a sequence of \(\{\underbrace{D, \dots, D}_{5}\}\). The strategy then proceeds to play
either \(C\) or \(D\) depending on which action had a higher average score for
the strategy (the average score is recalculated at each turn). A sequence
maximises its average score against Adaptive by locking the strategy into
unconditional cooperations following its opening 11 turns sequence. This is
achieved by cooperating twice against the strategies whilst it is cooperating
in its opening moves, because \(2 \times 3 + 0 \times 4 = 6\) is a
higher average score than \(1 \times 5 = 5\). Thus, there can be multiple best
responses to Adaptive, two best response sequences to the strategy, for \(N=15\),
are the sequences:

\[S_{1}^* = \{C, D, D, D, D, C, D, D, D, D, D, D, D, D, D\}\]

where \(U(S_{1}^*, \text{Adaptive}) = 3.4\) and

\[S_{2}^* = \{D, D, C, C, D, D, D, D, D, D, D, D, D, D, D\}\]

where \(U(S_{2}^*, \text{Adaptive}) = 3.4\).

However, identifying best responses and whether there are more than one is
a complex problem against specific opponents.
For this reason, best response sequences are not manually identified
but instead a genetic algorithm is used. A background on genetic algorithms and
the exact algorithm that is used in this Chapter are detailed in
section~\ref{section:genetic_algorithm}.

\section{Genetic Algorithm}\label{section:genetic_algorithm}

A genetic algorithm (GA) is a heuristic inspired by the process of natural
selection that belongs to the larger class of evolutionary algorithms. As stated
in~\cite{Whitley1994} GAs encode a potential solution to a
specific problem on a simple chromosome-like data structure, and apply
recombination operators to these structures in such a way as to preserve
critical information. GAs are often viewed as function
optimisers, although the range of problems to which they have been
applied~\cite{Hou1994, Jones1997, Yang1998} is quite broad.

An implementation of a GA begins with a population \(P\) of
potential solutions, a number of generations \(G \in \N\) and a cut-off or
bottleneck \(b < |P|\). At each generation the algorithm scores and potentially
removes each member of the population \(p_i \in P\). This is done by using a
mapping from a member of the population to an ordered set based on an evaluation
function \(f\), such that \(f(p_i) \to \R\). At the conclusion of each
generation the top \(b\) ranking members (or proportion of members) by score are
kept and the rest are discarded. By doing so, critical information regarding
the successful candidates is preserved and the population rebuilds on it using a
series of \textit{crossovers} and \textit{mutations}.

\begin{itemize}
    \item Crossovers take in 2 members of the population and return a new member
    based on some ``genes'' of the 2 selected members (commonly refereed to as parents).
    \item Mutations allow a change in a single member of the population. Mutation
    is commonly associated with a probability \(p_m\) which is the probability
    of a mutation happening, either at the individual or at each gene of the
    individual.
\end{itemize}

GA has the ability to avoid being trapped in local optimal solution like
traditional methods. This ability is due to the properties of crossover and
mutation. Crossover adds variance in the population by taking properties of both
parent members and introducing the evaluation of their combination to the
solution space. The algorithm can search multiple local optimal at once with its
population and start to identify the global optimal as members become more
optimised. Moreover, if an a member is trapped in a local optimal with its
fitness score, a mutation of a certain feature could potentially move their
position in the solution space to a better local optimal.

A diagrammatical representation of a generic GA is given in Figure~\ref{fig:ga_flow_diagram}.

\begin{figure}[!htbp]
    \centering
    \includestandalone[width=\textwidth]{src/chapters/06/tex/ga_flow_diagram}
    \caption{Generic flow diagram of a GA.}\label{fig:ga_flow_diagram}
\end{figure}

The purpose of a GA in this Chapter is to estimate the best response sequence to
a given opponent. Consequently, the members of the population correspond to
sequences \(S\) of length \(N\), and the evaluation function corresponds to the
average score per turn of the sequence against its opponent. The detailed GA of
this work is given by Algorithm~\ref{algorithm:genetic_algorithm}.

\begin{algorithm}[!htbp]
    \SetAlgoLined
    \KwIn{\(Q, N, b, p_m, G, K\)}
    \KwOut{Population at the last generation and the members' scores}
     \Begin{
     create initial population (Algorithm~\ref{algorithm:initial_population}) of members \(S\), where \(|S| = N\) and \(|P| = K\)\\
     \While{\(g_{i} < G\)}{
        score each member based on \(U(S_i, Q)\) for \(S_i \in P\) \\
        sort population based on scores \\
        keep \(b\) top members \\
        \While{\(|P|\) \(< K\)}{
            select 2 random members \\
            use members to create new member through crossover\\
            \For{gene in new member}{
            mutate gene with probability \(p_m\)}
            add new member to population\\
            }
     }}
     \caption{Get population of potential best response sequences}\label{algorithm:genetic_algorithm}
\end{algorithm}

The initial population is generated using Algorithm~\ref{algorithm:initial_population}.
Using a starting population of random guesses is a generally common approach in
the GA literature~\cite{Hou1994}. However, there is efficiency in using non
random starting populations~\cite{Drezner2005, Osaba2014}.
In the IPD the best responses to a board number of well established strategies
are either of the deterministic plays of always cooperating or defecting.
Thus, both of these are included in the initial population and the rest of
the population is filled with a combination of these two strategies.

\begin{algorithm}[!htbp]
        \SetAlgoLined
        \KwIn{\(K, N\)}
        \KwOut{A population of size \(K\).}
    
        \Begin{
        set of cuts $\gets$ \(K\) evenly spaced numbers over \([1, N]\) \\
        \For{\(c \in\) set of cuts}{
            first new member $\gets$  \(\{\underbrace{C, \dots, C}_{c}\} \cup \{\underbrace{D, \dots, D}_{N-c}\}\) \\
            second new member $\gets$ \(\{\underbrace{D, \dots, D}_{c}\} \cup \{\underbrace{C, \dots, C}_{N-c}\}\) \\
            add both members to population
        }
            }
     \caption{Create initial population of individuals \(S\)}\label{algorithm:initial_population}
\end{algorithm}

The GA of this Chapter has been implemented in the programming language Python
and it has been organised into a open source package called
\mintinline{python}{sequence_sensei} available at. %TODO archive
Figure~\ref{fig:get_initial_population} demonstrates the implementation of
Algorithm~\ref{algorithm:initial_population} in the package. Moreover,
Figure~\ref{fig:get_initial_population_example} gives a usage example of
generating a starting population of a given size using
\mintinline{python}{sequence_sensei}.
The bottom members of the populations are the sequences \(\{\underbrace{1, \dots, 1}_{N}\}\) and
\(\{\underbrace{0, \dots, 0}_{N}\}\), where \(0 \to D\) and \(1 \to C\), as expected. In
Figure~\ref{fig:get_initial_population_example} it is also illustrated how APL
can map binary numbers to the IPD actions.

\begin{figure}[!htbp]
\begin{sourcepy}
import numpy as np
def get_initial_population(half_size_of_population, sequence_length):
    """
    Generates an initial population of sequences. Note that the length
    of the population which is being generated is 2 * half_size_of_population.
    """
    cuts = np.linspace(1, sequence_length, half_size_of_population, dtype=int)
    sequences = []
    for cut in cuts:
        sequences.append(
            [1 for _ in range(cut)] + [0 for _ in range(sequence_length - cut)]
        )
        sequences.append(
            [0 for _ in range(cut)] + [1 for _ in range(sequence_length - cut)]
        )

    return sequences
\end{sourcepy}
\caption{Source code of the \mintinline{python}{get_initial_population} function
implemented in \mintinline{python}{sequence_sensei}.}\label{fig:get_initial_population}
\end{figure}

\begin{figure}[!htbp]
    \begin{usagepy}
>>> import sequence_sensei as ss
>>> import numpy as np

>>> initial_population = ss.get_initial_population(half_size_of_population=5, sequence_length=8)
>>> np.matrix(initial_population)
matrix([[1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0]])

>>> import axelrod as axl
>>> np.matrix([[axl.Action(gene) for gene in member] for member in initial_population])
matrix([[C, D, D, D, D, D, D, D],
        [D, C, C, C, C, C, C, C],
        [C, C, D, D, D, D, D, D],
        [D, D, C, C, C, C, C, C],
        [C, C, C, C, D, D, D, D],
        [D, D, D, D, C, C, C, C],
        [C, C, C, C, C, C, D, D],
        [D, D, D, D, D, D, C, C],
        [C, C, C, C, C, C, C, C],
        [D, D, D, D, D, D, D, D]], dtype=object)

\end{usagepy}
\caption{Example of using \mintinline{python}{get_initial_population} to
generate a population of \(s=10\) and \(N=8\).}\label{fig:get_initial_population_example}
\end{figure}

The crossover between two members of the population occurs by randomly selecting
a crossover point (smaller than \(N\)) and by combining the genes right to the
crossover point from the first parent and the left genes to the crossover point
from the second parent. Given two member of the population \(S_1 = \{C, C, C, C, C, C, C, C, C, C\}\)
and \(S_2 = \{C, D, C, D, C, D, C, D, C, D\}\) and given that the crossover point is 4:

\begin{itemize}
    \item the right genes to the crossover point for \(S_1\) are \(\{\underbrace{C, C, C, C}_{\text{to inherit}}, C, C, C, C, C, C\}\)
    \item the left genes to the crossover point for \(S_2\) are \(\{C, D, C, D,\underbrace{C, D, C, D, C, D}_{\text{to inherit}}\}\)
\end{itemize}

and thus the new member \(S_3\) is given by,

\[S_3 = \{C, C, C, C, C, D, C, D, C, D\}.\]

The crossover property has been implemented as a function in the \mintinline{python}{sequence_sensei},
the source code is given in Figure~\ref{fig:crossover_implementation}.

\begin{figure}[!htbp]
\begin{sourcepy}
import random

def crossover(sequence_one, sequence_two):
    sequence_length = len(sequence_one)
    crossover_point = random.randint(0, sequence_length)

    return sequence_one[:crossover_point] + sequence_two[crossover_point:]

\end{sourcepy}
\caption{Source code of the crossover property in \mintinline{python}{sequence_sensei}.}\label{fig:crossover_implementation}
\end{figure}

An example of the crossover between a \(S_1\) and \(S_2\) using the \mintinline{python}{crossover}
function is given in Figure~\ref{fig:crossover_usage}.

\begin{figure}[!htbp]
    \begin{usagepy}
>>> import random
>>> import sequence_sensei as ss

>>> turns = 10
>>> s_one = [1 for _ in range(turns)]
>>> s_two = [i % 2 for i in range(turns)]

>>> random.seed(0)
>>> new_member = ss.crossover(s_one, s_two)
>>> new_member
[1, 1, 1, 1, 1, 1, 0, 1, 0, 1]

\end{usagepy}
\caption{Usage example of crossover between \(S_1\) and \(S_2\)}\label{fig:crossover_usage}
\end{figure}

Following the crossover, a mutation is applied to new member before they are
added to the population. During the mutation property there is probability
\(p_m\) that each gene of the new member is flipped. The code to implementation
the mutation is given by Figure~\ref{fig:mutation_implementation}.

\begin{figure}[!htbp]
    \begin{sourcepy}
def mutation(gene, mutation_probability): if random.random() <
    mutation_probability: return abs(gene - 1) return gene
\end{sourcepy}
\caption{Source code of crossover and mutation properties in \mintinline{python}{sequence_sensei}.}\label{fig:mutation_implementation}
\end{figure}


\begin{figure}[!htbp]
    \begin{usagepy}
>>> new_member = [1, 1, 1, 1, 1, 1, 0, 1, 0, 1]

>>> random.seed(1)
>>> [ss.mutation(gene, mutation_probability=0.05) for gene in new_member]
[1, 1, 1, 1, 1, 1, 0, 1, 0, 0]

>>> random.seed(1)
>>> [round(random.random(), 3) for gene in new_member]
[0.134, 0.847, 0.764, 0.255, 0.495, 0.449, 0.652, 0.789, 0.094, 0.028]
\end{usagepy}
\caption{Mutation of new member.}\label{fig:crossover_usage}
\end{figure}

The only gene that has been mutated is the last gene. That means that the
sampled probabibilites were greatetr than the \(p_m = 0.05\). This can be checked
by Figure

\begin{figure}[!htbp]
    \centering
    \includestandalone[width=.6\textwidth]{src/chapters/06/tex/mutation_example}
    % \caption{Generic flow diagram of a GA.}\label{fig:ga_flow_diagram}
\end{figure}

The main function implemented in \mintinline{python}{sequence_sensei} for
performing a GA is the \mintinline{python}{evolved} function. The function has
several input arguments which correspond to the input as given in
Algorithm~\ref{algorithm:genetic_algorithm}. Details for the parameters' values
and the scoring process of the populations, and the process of generating a best
response sequence data set are presented in
section~\ref{section:generating_sequences}.

\section{Generating Best Response Sequences}\label{section:generating_sequences}

In order to generate the data set of best response sequences a collection of
\numberofstrategiesbestsequences strategies is considered as opponents. This
collection of strategies is accessible from the APL, and moreover,
the library is used to simulate the IPD games and to calculate the score
of the sequence strategies.

The APL projects contains a strategy called Cycler which plays a given sequence
\(S\). The Cycler strategy is considered to simulate the matches between the
\numberofstrategiesbestsequences strategies and the potential best response
sequences. An example of using the strategy Cycler is given in
Figure~\ref{fig:apl_simulations_cycler}. Figure~\ref{fig:apl_simulations_cycler}
illustrates how the matches of Tables~\ref{table:s_vs_cooperator}
and~\ref{table:s_vs_tft} can be simulated using APL, and moreover, how the score
of each strategy is accessible once the match has been performed.

\begin{figure}[!htbp]
    \begin{usagepy}
>>> import axelrod as axl

>>> players = [axl.Cycler('DDDCCCDDCC'), axl.Cooperator()]
>>> match = axl.Match(players, turns=10)
>>> match.play()
[(D, C), (D, C), (D, C), (C, C), (C, C), (C, C), (D, C), (D, C), (C, C), (C, C)]

>>> match.final_score_per_turn()
(4.0, 1.5)

>>> players = [axl.Cycler('DDDCCCDDCC'), axl.TitForTat()]
>>> match = axl.Match(players, turns=10)
>>> match.play()
[(D, C), (D, D), (D, D), (C, D), (C, C), (C, C), (D, C), (D, D), (C, D), (C, C)]

>>> match.final_score_per_turn()
(2.2, 2.2)

\end{usagepy}
\caption{Simulating matches using a Cycler to play a given sequence.}\label{fig:apl_simulations_cycler}
\end{figure}

The \numberofstrategiesbestsequences strategies used in this Chapter are found
in the Appendix alongside a citation of their paper of origin.
From these \numberofstrategiesbestsequences strategies, 62 are stochastic and
135 are deterministic. As it has been established, the outcome of a match
between two deterministic strategies never changes, as longs as the environment
does not include noise. In comparison, the outcomes of a match which includes even a single
stochastic strategy can be significantly different. In order to
capture distinct behaviours of stochastic strategies, and to be able to
reproduce the results of a match with a stochastic strategy, this work considers
\textit{computer seeding}. In Python a computer seed is used to initialise the
pseudo random number generator. Seeds are set before generating a random number,
and if the same seed is used on initialisation then the random output remains
the same. Thus, as long as a match is being seeded the behaviour of a stochastic
strategy can be reproduced, and different seeds lead to different series of
random numbers.

Consider the example of Random of Table~\ref{table:s_vs_random}. In
Figure~\ref{fig:random_apl_example} a different seed is being set five times
before the match between the sequence strategy and Random. The actions of the
Random strategy are different each time.

\begin{figure}[!htbp]
    \begin{usagepy}
>>> players = [axl.Cycler('DDDCCCDDCC'), axl.Random()]
>>> for seed in range(5):
...   axl.seed(seed)
...   match = axl.Match(players, turns=10)
...   actions = match.play()
...   print(actions, match.final_score_per_turn())
...   print("================================================================================")
[(D, D), (D, D), (D, C), (C, C), (C, D), (C, C), (D, D), (D, C), (C, C), (C, D)] (2.2, 2.2)
================================================================================
[(D, C), (D, D), (D, D), (C, C), (C, C), (C, C), (D, D), (D, D), (C, C), (C, C)] (2.4, 1.9)
================================================================================
[(D, D), (D, D), (D, C), (C, C), (C, D), (C, D), (D, D), (D, C), (C, D), (C, D)] (1.6, 2.6)
================================================================================
[(D, C), (D, D), (D, C), (C, D), (C, D), (C, C), (D, C), (D, D), (C, C), (C, C)] (2.6, 2.1)
================================================================================
[(D, C), (D, C), (D, C), (C, C), (C, C), (C, C), (D, D), (D, D), (C, D), (C, C)] (2.9, 1.9)
================================================================================

\end{usagepy}
\caption{Example code of using seeding to generate different instances of Random.
The above code snipped will always have the same output even if the matches are
``random'' because a computer seed is set before performing the
match.}\label{fig:random_apl_example}
\end{figure}

The data generating process selects one opponent from the collection of the
\numberofstrategiesbestsequences strategies and performs a series of GAs with
different parameters' values. The population at the last generation as well as
the scores of the sequences are exported in a csv file. Each time an opponent is
selected it is evaluated whether that opponent is deterministic or not. For
deterministic opponents the process is repeated only once, however, for
stochastic opponents a series of GAs are performed for 10 different seeded
version of the strategy. Thus, in total the process is repeated (\(135 + 62
\times 10\)) 755 times. Only a single value for the length of the
sequences has been considered and that the value of \(N=205\). A diagrammatical
representation of the collection process is given by
Figure~\ref{fig:data_generating_process_diagram}.

\begin{figure}[!htbp]
    \centering
    \includestandalone[width=\textwidth]{src/chapters/06/tex/data_generating_diagram}
    \caption{Diagrammatical representation of the best response
    sequences generating process.}\label{fig:data_generating_process_diagram}
\end{figure}

A series of GAs are performed for each of the of 755 distinct \(q\)s with
different parameter values. These values alongside a short explanation of the
parameters are given in Table~\ref{table:parameters_summary}. Moreover,
an example of an exported generation (which is exported in a csv format)
is given by Table~\ref{table:ouput_summary}.

\begin{table}[!htbp]
    \begin{center}
    \resizebox{.7\textwidth}{!}{
    \begin{tabular}{lllc} \toprule
    Parameter's symbol& Explanation                   & Values \\ \midrule
    \(N\)             & number of turns               & \(205\) \\
    \(p_m\)           & probability of gene mutating  & \(\{0.01, 0.05, 0.1\}\)\\
    \(b\)             & bottle neck                   & \(10, 20\) \\
    \(G\)             & number of generations         & \(2000\) \\
    \(s\)             & size of a population          & \(20, 30, 40\) \\ \bottomrule
    \end{tabular}}
    \end{center}
    \caption{The parameters of the genetic algorithm.}\label{table:parameters_summary}
\end{table}

\begin{table}[!htbp]
    \resizebox{\textwidth}{!}{
    \input{src/chapters/06/tex/output_table.tex}}
    \caption{An exampled of an exported csv. The output has \(s\) number of rows because
    each row contains information for each member of the population. Alternator is
    a deterministic strategy, consequently,
    the value of seed in NaN.}\label{table:ouput_summary}
\end{table}

An output (Table~\ref{table:ouput_summary}) has \(s\) number of rows because
each row contains information for each member of the population. At each of these
members are a potential best response sequence to the given opponent they have
been trained against. There are cases that more than a single member of the
final population is a best response. This is intuitive and expected following the
work of Chapter~\ref{chapter:memory_one} where it was proven that the utility
of even a memory one player is not concave, and thus, there is not one single
point which maximises the score against an IPD opponent. The total amount
of best response sequences which has been retrieved following the process
discussed in this section is 5503.

\section{Chapter Summary}

This Chapter has explored the concept of best responses in the IPD game in the
form of static sequences of moves. It has identified a successful method of
generating best response sequences using an evolutionary algorithm and executed
analysis to find these solutions to the majority of opponents listed in the APL.

More specifically, a total of \numberofstrategiesbestsequences opponents from
APL were used. Several of the strategies in the project are stochastic and
computer seeded version of these strategies were used to explore their different
behaviours. A given opponent can have more than a single best response to it, and
as a result, a total of 5503 best response sequences to a total of 755 opponents
have been calculated. The data set has been archive and is available at
\cite{Glynatsi2020_sequences}.

The main purpose of this Chapter has been to generate the bespoke data set,
which is to be used as training data set in the following Chapter.
