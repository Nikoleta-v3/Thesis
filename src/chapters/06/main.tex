\chapter{Best Response Sequences in the Iterated Prisoner's Dilemma}\label{chapter:best_response_sequence}

\begin{center}
    The research reported in this Chapter has been carried out with:

    Axerod-Python library version: 4.2.0 \\
    Associated data set: \cite{Glynatsi2020_sequences} \\ \vspace{.5cm}
\end{center}

\section{Introduction}

In this Chapter best response strategies are explored in the form
of static sequences of moves, in order to generate a large data set of best
response sequences to a collection of opponents.

The data set is generated by considering best response sequences in finite IPD
matches of 205 turns against \numberofstrategiesbestsequences strategies
available in the APL. These best response sequences are not obtained explicitly
but instead are estimated heuristically using a genetic algorithm devised for
this purpose.

The purpose of a large collection of best response sequences is
to serve as training data in Chapter~\ref{chapter:lstm} which aims to train a
recurrent neural network as an IPD strategy. In Chapter~\ref{chapter:lstm} the
usage of the bespoke data set, which has been archived and made publicly
available~\cite{Glynatsi2020_sequences}, is be discussed in more details. This
Chapter is structured as follow:

\begin{itemize}
    \item section~\ref{section:ipd_as_sequences} formalises the use of sequences to express a player in a
    finite IPD match.
    \item section~\ref{section:genetic_algorithm} describes the genetic algorithm
    used to estimate best response
    sequences.
    \item section~\ref{section:generating_sequences} details the process of
    generating best response sequences to a collection of
    \numberofstrategiesbestsequences strategies, and presents a brief analysis
    of its results.
\end{itemize}

\section{Iterated Prisoner Dilemma Strategies as Sequences}\label{section:ipd_as_sequences}

In a finite \(N\) round IPD match a player that does not react to their opponent
is defined by a sequence,

\begin{equation}
    S \in \{C, D\} ^ n, \text{where } 1 \leq n \leq N.
\end{equation}

Strategies that base their actions on sequences are already established in the
literature~\cite{Beaufils1997}. Such strategies include Periodic Player \(CD\), Periodic Player \(DC\),
Periodic Player \(CCD\) and Periodic Player \(DDC\)~\cite{Li2011, Mittal2009},
or as referred to in~\cite{Knight2016} Cycler \(CD\), Cycler \(DC\),
Cycler \(CCD\) and Cycler \(DDC\). These are strategies that given sequences
periodically, compared to these, the strategies concerned with here play a given
sequence only once. Thus \(n = N\).

As an example consider a match of 10 turns between the strategy \(S = \{D, D, D,
C, C, C, D, D, C, C\}\) and a Cooperator. The match between the two strategies
is captured by Table~\ref{table:s_vs_cooperator} where \(U(s_1, s_2)\in
\mathbb{R}^2\) is the average scores per turn scored by strategies \(s_1\) and
\(s_2\).

\begin{table}[htb]
\centering
\begin{tabular}{cccccccccccc}
    & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4}  & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8}  & \textbf{9} & \textbf{10} & 
    \(U(S, \text{Cooperator})\) \\ \midrule
    \(S\) & \(D\) & \(D\) & \(D\) & \(C\) & \(C\) & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & 4.0 \\
    Cooperator & \(C\) & \(C\) & \(C\) & \(C\) & \(C\) & \(C\) & \(C\) & \(C\) & \(C\) & \(C\) & 1.5 \\ \bottomrule
\end{tabular}
\caption{The interactions of a 10 turns match between \(S = \{D, D, D, C, C, C, D, D, C, C\}\) and
Cooperator as well as the average score per turn achieved by each strategy.}\label{table:s_vs_cooperator}
\end{table}

A sequence strategy \(S\) can play against strategies that react to the history.
For example against Tit Tor Tat as demonstrated by Table~\ref{table:s_vs_tft},

\begin{table}[htb]
\centering
\begin{tabular}{cccccccccccc}
    & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4}  & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8}  & \textbf{9} & \textbf{10} &
    \(U(S, \text{Tit For Tat})\) \\ \midrule
    \(S\) & \(D\) & \(D\) & \(D\) & \(C\) & \(C\) & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & 2.2 \\
    Tit For Tat & \(C\) & \(D\) & \(D\) & \(D\) & \(C\) & \(C\) & \(C\) & \(D\) & \(D\) & \(C\) & 2.2 \\ \bottomrule
\end{tabular}
\caption{The interactions and average score per turn of a 10 turns match between
\(S = \{D, D, D, C, C, C, D, D, C, C\}\) and Tit For Tat.}\label{table:s_vs_tft}
\end{table}

and against stochastic strategies such as Random. Random cooperates with a
probability of \(0.5\) at ech turn. The actions of the strategy are
probabilistic and not deterministic and due to that its actions can differ
between repetitions. The actions of stochastic strategies that react to the
history also differ between repetitions even when the history of the match is
the same. Tables~\ref{table:s_vs_random} and~\ref{table:s_vs_random}, both
capture a match between \(S\) and a Random player. For a match of 10 turns
Random has a total of \(2^{10}\) %TODO check my maths is right possible plays.
In order to capture several instances of stochastic strategies' plays computer
seeding is used in section~\ref{section:generating_sequences}.

\begin{table}[htb]
\centering
\begin{tabular}{cccccccccccc}
    & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4}  & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8}  & \textbf{9} & \textbf{10} &
    \(U(S, \text{Random})\) \\ \midrule
    \(S\) & \(D\) & \(D\) & \(D\) & \(C\) & \(C\) & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & 2.2 \\
    Random & \(D\) & \(D\) & \(C\) & \(C\) & \(D\) & \(C\) & \(D\) & \(C\) & \(C\) & \(D\) & 2.2 \\ \bottomrule
\end{tabular}
\caption{The interactions and average score per turn of a 10 turns match between
\(S = \{D, D, D, C, C, C, D, D, C, C\}\) and Random.}\label{table:s_vs_random}
\end{table}

\begin{table}[htb]
\centering
\begin{tabular}{cccccccccccc}
    & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4}  & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8}  & \textbf{9} & \textbf{10} & \(U(S, \text{Random})\) \\ 
    \midrule 
    \(S\) & \(D\) & \(D\) & \(D\) & \(C\) & \(C\) & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & 2.4 \\
    Random & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & \(C\) & \(D\) & \(D\) & \(C\) & \(C\) & 1.9 \\ \bottomrule
\end{tabular}
\caption{The interactions and average score per turn of a 10 turns match between
\(S = \{D, D, D, C, C, C, D, D, C, C\}\) and Random. The actions make by Random
are different to that Table~\ref{table:s_vs_random}.}\label{table:s_vs_random_2}
\end{table}

As discussed in Chapters~\ref{chapter:introduction} and~\ref{chapter:memory_one},
a best response strategy is a strategy that achieves that most favourable outcome.
Thus a best response sequence against a given opponent \(Q\) corresponds
to a sequence \(S^*\) for which the average score per turn is maximised,
as given in~(\ref{eq:best_response_sequence}).

\begin{equation}\label{eq:best_response_sequence}
    \begin{aligned}
    \max_{S^*}: & U(S^*, Q)
    \end{aligned}
\end{equation}

Identifying best responses to some opponents can be a trivial problem, the
optimal sequence against a Cooperator is in an all \(D\) sequence, however,
for some strategies identifying best responses is a complex problem. Note that
in fact the sequence \(\{\underbrace{D, \dots, D}_{N}\}\) is a best response
against any sequence player whose plays are independent of the history.

Futhermore, there are strategies that have multiple best response sequences. For
instance the strategy Adaptive introduced in~\cite{Li2011}. Adaptive opens by
playing a sequence of \(\{\underbrace{C, \dots, C}_{6}\}\) followed by a
sequence of \(\{\underbrace{D, \dots, D}_{5}\}\). The strategy then proceeds to
play either \(C\) or \(D\) depending on which action had a higher average score
for the strategy (the average score is recalculated at each turn). A sequence
maximises its average score against Adaptive by locking the strategy into
unconditional cooperations following its opening 11 turns sequence. In order
for cooperation to be the most favourable action for Adaptive needs to achieve
two mutual cooperations at its opening sequence. Because  the score achieved
by playing \(C\) is \(2 \times 3 + 0 \times 4 = 6\) which is greater than the
score achieved by \(D\) \(1 \times 5 = 5\).
Thus, any sequence which incorporates two cooperations in the first 6 turns
and defects thereafter is a best response sequence to Adaptive. Thus, there
can be \(2^{6}\) best response sequences. For example \(S_{1}^*\) and \(S_{2}^*\),

\[S_{1}^* = \{C, D, D, D, D, C, D, D, D, D, D, D, D, D, D\}\]

\[S_{2}^* = \{D, D, C, C, D, D, D, D, D, D, D, D, D, D, D\}\]

where \(U(S_{1}^*, \text{Adaptive}) = U(S_{2}^*, \text{Adaptive}) = 3.4\).

Due to identifying best response sequences to some opponents being a complex
problem, and moreover, multiple best response sequences existing for some
opponents the best response sequences are not manually identified. Instead a
genetic algorithm is used to estimate them. A background on genetic algorithms
as well as the details of the specific genetic algorithm devised for this Chapter
are presented in the following section.

\section{Genetic Algorithm}\label{section:genetic_algorithm}

A genetic algorithm (GA) is a heuristic inspired by the process of natural
selection that belongs to the larger class of evolutionary algorithms. As stated
in~\cite{Whitley1994} GAs encode a potential solution to a
specific problem on a simple chromosome-like data structure, and apply
recombination operators to these structures in such a way as to preserve
critical information. GAs are often viewed as function
optimisers, although the range of problems to which they have been
applied is quite broad~\cite{Hou1994, Jones1997, Yang1998}.

An implementation of a GA begins with a \textit{population} \(P\) of
potential solutions, a number of \textit{generations} \(G \in \N\) and a cut-off or
\textit{bottleneck} \(b < |P|\). At each generation the algorithm scores and potentially
removes each member of the population \(p_i \in P\). This is done by using a
mapping from a member of the population to an ordered set based on an evaluation
function \(f\), such that \(f(p_i) \to \R\), and by only keeping the top \(b\)
ranking members (or proportion of members) by score at the end of each
generation. The rest of the member are discarded. By keeping the top ranked
individuals critical information regarding the successful candidates is
preserved and the population rebuilds on it using a series of
\textit{crossovers} and \textit{mutations}.

\begin{itemize}
    \item During a crossovers 2 members of the population are selected and a new
    member is created based on a ``gene'' combination of the 2 selected members
    (commonly referred to as parents).
    \item Mutation is a probabilistic change that occurs at an individual,
    Mutation is commonly associated with a probability, denoted as \(p_m\),
    which is the probability of a mutation happening, either at the individual
    or at each gene of the individual.
\end{itemize}

A diagrammatical representation of a generic GA is given in Figure~\ref{fig:ga_flow_diagram}.

\begin{figure}[!htbp]
    \centering
    \includestandalone[width=\textwidth]{src/chapters/06/tex/ga_flow_diagram}
    \caption{Generic flow diagram of a GA.}\label{fig:ga_flow_diagram}
\end{figure}

The purpose of a GA here is to estimate the best response sequence to
a given opponent \(Q\). Consequently, the members of the population correspond to
sequences,

\[S_i \in P \text{ where } |S_i| = N\]

and the evaluation function corresponds to the
average score per turn of the sequence against \(Q\),

\[U(S_i, Q) \to \R \text{ for } S_i \in P\]

More specifically, the specific GA used in this Chapter is given
by Algorithm~\ref{algorithm:genetic_algorithm}.

\begin{algorithm}[!htbp]
    \SetAlgoLined
    \KwIn{\(Q, N, b, p_m, G, K\)}
    \KwOut{The populations at each generation and the members' scores}
     \Begin{
     create initial population (Algorithm~\ref{algorithm:initial_population}) of members \(S\), where \(|S| = N\) and \(|P| = K\)\\
     \While{\(g_{i} < G\)}{
        score each member based on \(U(S_i, Q)\) for \(S_i \in P\) \\
        sort population based on scores \\
        keep \(b\) top members \\
        \While{\(|P|\) \(< K\)}{
            select 2 random members \\
            use members to create new member through crossover\\
            \For{gene in new member}{
            mutate gene with probability \(p_m\)}
            add new member to population\\
            }
     }}
     \caption{GA for estimating best response sequences to a given opponent \(Q\).}\label{algorithm:genetic_algorithm}
\end{algorithm}

The initial population is created using Algorithm~\ref{algorithm:initial_population}.

\begin{algorithm}[!htbp]
    \SetAlgoLined
    \KwIn{\(K, N\)}
    \KwOut{A population of size \(K\).}

    \Begin{
    set of cuts $\gets$ \(K\) evenly spaced numbers over \([1, N]\) \\
    \For{\(c \in\) set of cuts}{
        first new member $\gets$  \(\{\underbrace{C, \dots, C}_{c}\} \cup \{\underbrace{D, \dots, D}_{N-c}\}\) \\
        second new member $\gets$ \(\{\underbrace{D, \dots, D}_{c}\} \cup \{\underbrace{C, \dots, C}_{N-c}\}\) \\
        add both members to population
    }
        }
 \caption{Create initial population of individuals \(S\)}\label{algorithm:initial_population}
\end{algorithm}

Using a starting population of random guesses is a generally common approach in
the GA literature~\cite{Hou1994}. However, there is efficiency in using non
random starting populations~\cite{Drezner2005, Osaba2014}.
As discussed in section~\ref{section:ipd_as_sequences} the best response sequence
to any strategy that does not react to the history is a Defector. Moreover,
the best response sequence to several strategies such as Tit For Tat and Grudger,
for a finite match, is \(\{\underbrace{C, \dots, C}_{N-1}, D\}\). These are
sequences that have been incorporated in the initial population. More specifically,
Algorithm~\ref{algorithm:initial_population} consider all the possible combinations
of:

\[\bullet \{\underbrace{C, \dots, C}_{c}, \underbrace{D, \dots, D}_{N-c}\} \text{ for } c \in {1, 2, \dots, N-1} \text{ and}\]
\[\bullet \{\underbrace{D, \dots, D}_{c}, \underbrace{C, \dots, C}_{N-c}\} \text{ for } c \in {1, 2, \dots, N-1.}\]

The GA of Algorithm~\ref{algorithm:genetic_algorithm} has been implemented in the programming language Python
and it has been organised into a open source package called
\mintinline{python}{sequence_sensei} available at. %TODO archive
The properties of creating an initial population, crossover and mutation have been
implemented as individual functions.
The implementation of Algorithm~\ref{algorithm:initial_population} in the package
is given by Figure~\ref{fig:get_initial_population}.

\begin{figure}[!htbp]
\begin{sourcepy}
import numpy as np
def get_initial_population(half_size_of_population, sequence_length):
    """
    Generates an initial population of sequences. Note that the length
    of the population which is being generated is 2 * half_size_of_population.
    """
    cuts = np.linspace(1, sequence_length, half_size_of_population, dtype=int)
    sequences = []
    for cut in cuts:
        sequences.append(
            [1 for _ in range(cut)] + [0 for _ in range(sequence_length - cut)]
        )
        sequences.append(
            [0 for _ in range(cut)] + [1 for _ in range(sequence_length - cut)]
        )

    return sequences
\end{sourcepy}
\caption{Source code for the function \mintinline{python}{get_initial_population}
implemented in \mintinline{python}{sequence_sensei} which is used to create an
initial population of a given size.}\label{fig:get_initial_population}
\end{figure}

Figure~\ref{fig:get_initial_population_example} gives an example of creating an
initial population using the package. Note that the sequences are of 0s and 1s
and not IPD actions. The APL project can map binary number to actions such that
\(0 \to D\) and \(1 \to C\). This is also demonstrated in
Figure~\ref{fig:get_initial_population_example}.

\begin{figure}[!htbp]
    \begin{usagepy}
>>> import sequence_sensei as ss
>>> import numpy as np

>>> initial_population = ss.get_initial_population(half_size_of_population=5, sequence_length=8)
>>> np.matrix(initial_population)
matrix([[1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 0, 0, 0, 0, 0, 0],
        [0, 0, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0, 0, 0, 0],
        [0, 0, 0, 0, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0]])

>>> import axelrod as axl
>>> np.matrix([[axl.Action(gene) for gene in member] for member in initial_population])
matrix([[C, D, D, D, D, D, D, D],
        [D, C, C, C, C, C, C, C],
        [C, C, D, D, D, D, D, D],
        [D, D, C, C, C, C, C, C],
        [C, C, C, C, D, D, D, D],
        [D, D, D, D, C, C, C, C],
        [C, C, C, C, C, C, D, D],
        [D, D, D, D, D, D, C, C],
        [C, C, C, C, C, C, C, C],
        [D, D, D, D, D, D, D, D]], dtype=object)

\end{usagepy}
\caption{Example of using \mintinline{python}{get_initial_population} to
generate a population of \(s=10\) and \(N=8\).}\label{fig:get_initial_population_example}
\end{figure}

In the GA, as given by Algorithm~\ref{algorithm:genetic_algorithm}, the
crossover occurs by randomly selecting two member of the population, while \(|P|
< K\), and randomly selecting a crossover over point. Note that the crossover
over point need to be smaller than \(N\). The new member initially inherits the
genes right to the crossover point from the first parent, and then the left
genes to the crossover point from the second parent.

For instance, given two member of the population \(S_1 = \{C, C, C, C, C, C, C, C, C, C\}\)
and \(S_2 = \{C, D, C, D, C, D, C, D, C, D\}\) and given that the crossover point is
4:

\begin{itemize}
    \item The right genes to the crossover point for \(S_1\) are \(\{\underbrace{C, C, C, C}_{\text{to inherit}}, C, C, C, C, C, C\}.\)
    \item The left genes to the crossover point for \(S_2\) are \(\{C, D, C, D,\underbrace{C, D, C, D, C, D}_{\text{to inherit}}\}.\)
\end{itemize}

Thus, the new member \(S_3\) is given by,

\[S_3 = \{\underbrace{C, C, C, C}_{\text{from } S_1}, \underbrace{C, D, C, D, C, D}_{\text{from } S_2}\}.\]

The implementation of crossover in \mintinline{python}{sequence_sensei} is given
by Figure~\ref{fig:crossover_implementation}, and Figure~\ref{fig:crossover_usage}
demonstrates the usage of the \mintinline{python}{crossover} function to crossover
\(S_1\) and \(S_2\).

\begin{figure}[!htbp]
\begin{sourcepy}
import random

def crossover(sequence_one, sequence_two):
    sequence_length = len(sequence_one)
    crossover_point = random.randint(0, sequence_length)

    return sequence_one[:crossover_point] + sequence_two[crossover_point:]

\end{sourcepy}
\caption{Source code of the \mintinline{python}{crossover} function.}\label{fig:crossover_implementation}
\end{figure}

\begin{figure}[!htbp]
    \begin{usagepy}
>>> import random
>>> import sequence_sensei as ss

>>> turns = 10
>>> s_one = [1 for _ in range(turns)]
>>> s_two = [i % 2 for i in range(turns)]

>>> random.seed(0)
>>> new_member = ss.crossover(s_one, s_two)
>>> new_member
[1, 1, 1, 1, 1, 1, 0, 1, 0, 1]

\end{usagepy}
\caption{An example of using \mintinline{python}{crossover} function to crossover \(S_1\) and \(S_2\)}\label{fig:crossover_usage}
\end{figure}

Following the crossover between two members, a mutation is applied to new member
before it is are added to the population. Mutation has been implemented as a
given probability \(p_m\) that each gene of the new member is flipped. A total
of \(N\) random numbers between \([0, 1]\) are sampled. If the sampled
probability at time \(i\) in less than \(p_m\) then the \(i^{th}\) gene of the
individual is flipped, as demonstrated by
Figure~\ref{fig:mutation_diagrammatic_example}.

\begin{figure}[!htbp]
    \centering
    \includestandalone[width=.6\textwidth]{src/chapters/06/tex/mutation_example}
    \caption{Mutation example of \(S_3\).}\label{fig:mutation_diagrammatic_example}
\end{figure}

The implementation of mutation in \mintinline{python}{sequence_sensei} is given
by Figure~\ref{fig:mutation_implementation}, and an example of mutating \(S_3\)
using the function is given in Figure~\ref{fig:mutation_usage}.

\begin{figure}[!htbp]
    \begin{sourcepy}
def mutation(gene, mutation_probability): if random.random() <
    mutation_probability: return abs(gene - 1) return gene
\end{sourcepy}
\caption{Source code of the \mintinline{python}{mutation} function.}\label{fig:mutation_implementation}
\end{figure}

\begin{figure}[!htbp]
    \begin{usagepy}
>>> new_member = [1, 1, 1, 1, 1, 1, 0, 1, 0, 1]

>>> random.seed(1)
>>> [ss.mutation(gene, mutation_probability=0.05) for gene in new_member]
[1, 1, 1, 1, 1, 1, 0, 1, 0, 0]

\end{usagepy}
\caption{An example of using the \mintinline{python}{mutation} function to mutate
\(S_3\).}\label{fig:mutation_usage}
\end{figure}

The main function implemented in \mintinline{python}{sequence_sensei} for
performing a GA is the \mintinline{python}{evolved} function. The function has
several input arguments which correspond to the inputs of
Algorithm~\ref{algorithm:genetic_algorithm}. In the following section the
\mintinline{python}{evolved} function is used to run several trials and estimate
best response sequence. The parameters' values for each run will be presented there.
Moreover, the details of the best response sequence collection against the
\numberofstrategiesbestsequences strategies are presented in the following section.

\section{Generating Best Response Sequences}\label{section:generating_sequences}

In order to generate the data set of best response sequences a collection of
\numberofstrategiesbestsequences strategies is considered as opponents. This
collection of strategies is accessible from the APL, and moreover,
the library is used to simulate the IPD games and to calculate the score
of the sequence strategies.

The APL projects contains a strategy called Cycler which plays a given sequence
\(S\). The Cycler strategy is considered to simulate the matches between the
\numberofstrategiesbestsequences strategies and the potential best response
sequences. An example of using the strategy Cycler is given in
Figure~\ref{fig:apl_simulations_cycler}. Figure~\ref{fig:apl_simulations_cycler}
illustrates how the matches of Tables~\ref{table:s_vs_cooperator}
and~\ref{table:s_vs_tft} can be simulated using APL, and moreover, how the score
of each strategy is accessible once the match has been performed.

\begin{figure}[!htbp]
    \begin{usagepy}
>>> import axelrod as axl

>>> players = [axl.Cycler('DDDCCCDDCC'), axl.Cooperator()]
>>> match = axl.Match(players, turns=10)
>>> match.play()
[(D, C), (D, C), (D, C), (C, C), (C, C), (C, C), (D, C), (D, C), (C, C), (C, C)]

>>> match.final_score_per_turn()
(4.0, 1.5)

>>> players = [axl.Cycler('DDDCCCDDCC'), axl.TitForTat()]
>>> match = axl.Match(players, turns=10)
>>> match.play()
[(D, C), (D, D), (D, D), (C, D), (C, C), (C, C), (D, C), (D, D), (C, D), (C, C)]

>>> match.final_score_per_turn()
(2.2, 2.2)

\end{usagepy}
\caption{Simulating matches using a Cycler to play a given sequence.}\label{fig:apl_simulations_cycler}
\end{figure}

The \numberofstrategiesbestsequences strategies used in this Chapter are found
in the Appendix alongside a citation of their paper of origin.
From these \numberofstrategiesbestsequences strategies, 62 are stochastic and
135 are deterministic. As it has been established, the outcome of a match
between two deterministic strategies never changes, as longs as the environment
does not include noise. In comparison, the outcomes of a match which includes even a single
stochastic strategy can be significantly different. In order to
capture distinct behaviours of stochastic strategies, and to be able to
reproduce the results of a match with a stochastic strategy, this work considers
\textit{computer seeding}. In Python a computer seed is used to initialise the
pseudo random number generator. Seeds are set before generating a random number,
and if the same seed is used on initialisation then the random output remains
the same. Thus, as long as a match is being seeded the behaviour of a stochastic
strategy can be reproduced, and different seeds lead to different series of
random numbers.

Consider the example of Random of Table~\ref{table:s_vs_random}. In
Figure~\ref{fig:random_apl_example} a different seed is being set five times
before the match between the sequence strategy and Random. The actions of the
Random strategy are different each time.

\begin{figure}[!htbp]
    \begin{usagepy}
>>> players = [axl.Cycler('DDDCCCDDCC'), axl.Random()]
>>> for seed in range(5):
...   axl.seed(seed)
...   match = axl.Match(players, turns=10)
...   actions = match.play()
...   print(actions, match.final_score_per_turn())
...   print("================================================================================")
[(D, D), (D, D), (D, C), (C, C), (C, D), (C, C), (D, D), (D, C), (C, C), (C, D)] (2.2, 2.2)
================================================================================
[(D, C), (D, D), (D, D), (C, C), (C, C), (C, C), (D, D), (D, D), (C, C), (C, C)] (2.4, 1.9)
================================================================================
[(D, D), (D, D), (D, C), (C, C), (C, D), (C, D), (D, D), (D, C), (C, D), (C, D)] (1.6, 2.6)
================================================================================
[(D, C), (D, D), (D, C), (C, D), (C, D), (C, C), (D, C), (D, D), (C, C), (C, C)] (2.6, 2.1)
================================================================================
[(D, C), (D, C), (D, C), (C, C), (C, C), (C, C), (D, D), (D, D), (C, D), (C, C)] (2.9, 1.9)
================================================================================

\end{usagepy}
\caption{Example code of using seeding to generate different instances of Random.
The above code snipped will always have the same output even if the matches are
``random'' because a computer seed is set before performing the
match.}\label{fig:random_apl_example}
\end{figure}

The data generating process selects one opponent from the collection of the
\numberofstrategiesbestsequences strategies and performs a series of GAs with
different parameters' values. The population at the last generation as well as
the scores of the sequences are exported in a csv file. Each time an opponent is
selected it is evaluated whether that opponent is deterministic or not. For
deterministic opponents the process is repeated only once, however, for
stochastic opponents a series of GAs are performed for 10 different seeded
version of the strategy. Thus, in total the process is repeated (\(135 + 62
\times 10\)) 755 times. Only a single value for the length of the
sequences has been considered and that the value of \(N=205\). A diagrammatical
representation of the collection process is given by
Figure~\ref{fig:data_generating_process_diagram}.

\begin{figure}[!htbp]
    \centering
    \includestandalone[width=\textwidth]{src/chapters/06/tex/data_generating_diagram}
    \caption{Diagrammatical representation of the best response
    sequences generating process.}\label{fig:data_generating_process_diagram}
\end{figure}

A series of GAs are performed for each of the of 755 distinct \(q\)s with
different parameter values. These values alongside a short explanation of the
parameters are given in Table~\ref{table:parameters_summary}. Moreover,
an example of an exported generation (which is exported in a csv format)
is given by Table~\ref{table:ouput_summary}.

\begin{table}[!htbp]
    \begin{center}
    \resizebox{.7\textwidth}{!}{
    \begin{tabular}{lllc} \toprule
    Parameter's symbol& Explanation                   & Values \\ \midrule
    \(N\)             & number of turns               & \(205\) \\
    \(p_m\)           & probability of gene mutating  & \(\{0.01, 0.05, 0.1\}\)\\
    \(b\)             & bottle neck                   & \(10, 20\) \\
    \(G\)             & number of generations         & \(2000\) \\
    \(s\)             & size of a population          & \(20, 30, 40\) \\ \bottomrule
    \end{tabular}}
    \end{center}
    \caption{The parameters of the genetic algorithm.}\label{table:parameters_summary}
\end{table}

\begin{table}[!htbp]
    \resizebox{\textwidth}{!}{
    \input{src/chapters/06/tex/output_table.tex}}
    \caption{An exampled of an exported csv. The output has \(s\) number of rows because
    each row contains information for each member of the population. Alternator is
    a deterministic strategy, consequently,
    the value of seed in NaN.}\label{table:ouput_summary}
\end{table}

An output (Table~\ref{table:ouput_summary}) has \(s\) number of rows because
each row contains information for each member of the population. At each of these
members are a potential best response sequence to the given opponent they have
been trained against. There are cases that more than a single member of the
final population is a best response. This is intuitive and expected following the
work of Chapter~\ref{chapter:memory_one} where it was proven that the utility
of even a memory one player is not concave, and thus, there is not one single
point which maximises the score against an IPD opponent. The total amount
of best response sequences which has been retrieved following the process
discussed in this section is 5503.

\section{Chapter Summary}

This Chapter has explored the concept of best responses in the IPD game in the
form of static sequences of moves. It has identified a successful method of
generating best response sequences using an evolutionary algorithm and executed
analysis to find these solutions to the majority of opponents listed in the APL.

More specifically, a total of \numberofstrategiesbestsequences opponents from
APL were used. Several of the strategies in the project are stochastic and
computer seeded version of these strategies were used to explore their different
behaviours. A given opponent can have more than a single best response to it, and
as a result, a total of 5503 best response sequences to a total of 755 opponents
have been calculated. The data set has been archive and is available at
\cite{Glynatsi2020_sequences}.

The main purpose of this Chapter has been to generate the bespoke data set,
which is to be used as training data set in the following Chapter.
